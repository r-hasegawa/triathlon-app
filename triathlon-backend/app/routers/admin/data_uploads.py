"""
app/routers/admin/data_uploads.py
ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ï¼ˆFlexibleCSVServiceä¸ä½¿ç”¨ - å…ƒã®admin.pyæ–¹å¼ï¼‰
"""

from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form, Query
from sqlalchemy.orm import Session
from typing import List, Optional
import pandas as pd
import xml.etree.ElementTree as ET
import io

from app.database import get_db
from app.models.user import AdminUser
from app.models.competition import Competition
from app.utils.dependencies import get_current_admin
from .utils import generate_batch_id, detect_encoding

router = APIRouter()


@router.post("/upload/skin-temperature")
async def upload_skin_temperature(
    competition_id: str = Form(...),
    files: List[UploadFile] = File(...),
    db: Session = Depends(get_db),
    current_admin: AdminUser = Depends(get_current_admin)
):
    """ä½“è¡¨æ¸©ãƒ‡ãƒ¼ã‚¿ï¼ˆhalshareï¼‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ - å…ƒã®admin.pyæ–¹å¼"""
    
    competition = db.query(Competition).filter_by(competition_id=competition_id).first()
    if not competition:
        raise HTTPException(status_code=404, detail="Competition not found")
    
    results = []
    
    for file in files:
        batch_id = generate_batch_id(file.filename)
        
        try:
            content = await file.read()
            encoding = detect_encoding(content)
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œï¼‰
            try:
                df = pd.read_csv(io.BytesIO(content), encoding=encoding)
            except UnicodeDecodeError:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                try:
                    df = pd.read_csv(io.BytesIO(content), encoding='utf-8')
                except Exception:
                    df = pd.read_csv(io.BytesIO(content), encoding='shift-jis')
            
            # å¿…è¦ãªåˆ—ã®ç¢ºèª
            required_cols = ['halshareWearerName', 'halshareId', 'datetime', 'temperature']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                results.append({
                    "file": file.filename,
                    "error": f"å¿…é ˆåˆ—ãŒä¸è¶³: {missing_cols}",
                    "status": "failed"
                })
                continue
            
            # UploadBatchä½œæˆ
            from app.models.flexible_sensor_data import UploadBatch, SensorType, UploadStatus, SkinTemperatureData
            batch = UploadBatch(
                batch_id=batch_id,
                sensor_type=SensorType.SKIN_TEMPERATURE,
                file_name=file.filename,
                competition_id=competition_id,
            )
            db.add(batch)
            
            success_count = 0
            failed_count = 0
            
            # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
            for _, row in df.iterrows():
                try:
                    # ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã¨æ­£è¦åŒ–ï¼ˆã‚¯ã‚©ãƒ¼ãƒˆãƒ»ã‚¹ãƒšãƒ¼ã‚¹é™¤å»ï¼‰
                    wearer_name = str(row['halshareWearerName']).strip()
                    sensor_id = str(row['halshareId']).strip()
                    datetime_str = str(row['datetime']).strip()
                    
                    # ã‚¯ã‚©ãƒ¼ãƒˆé™¤å»å‡¦ç†
                    if sensor_id.startswith(' "') and sensor_id.endswith('"'):
                        sensor_id = sensor_id[2:-1]  # ' "å€¤" â†’ å€¤
                    elif sensor_id.startswith('"') and sensor_id.endswith('"'):
                        sensor_id = sensor_id[1:-1]   # "å€¤" â†’ å€¤
                    
                    if datetime_str.startswith(' "') and datetime_str.endswith('"'):
                        datetime_str = datetime_str[2:-1]  # ' "æ—¥æ™‚" â†’ æ—¥æ™‚
                    elif datetime_str.startswith('"') and datetime_str.endswith('"'):
                        datetime_str = datetime_str[1:-1]   # "æ—¥æ™‚" â†’ æ—¥æ™‚
                    
                    # æœ€çµ‚çš„ãªç©ºç™½é™¤å»
                    wearer_name = wearer_name.strip()
                    sensor_id = sensor_id.strip()
                    datetime_str = datetime_str.strip()
                    
                    # ç©ºå€¤ãƒã‚§ãƒƒã‚¯
                    if not wearer_name or wearer_name in ['nan', 'None']:
                        raise ValueError("ç€ç”¨è€…åãŒç©º")
                    
                    if not sensor_id or sensor_id in ['nan', 'None']:
                        raise ValueError("ã‚»ãƒ³ã‚µãƒ¼IDãŒç©º")
                    
                    if not datetime_str or datetime_str in ['nan', 'None']:
                        raise ValueError("æ—¥æ™‚ãŒç©º")
                    
                    if pd.isna(row['temperature']):
                        raise ValueError("æ¸©åº¦ãŒç©º")
                    
                    # æ—¥æ™‚ãƒ‘ãƒ¼ã‚¹ï¼ˆæ­£è¦åŒ–å¾Œï¼‰
                    try:
                        parsed_datetime = pd.to_datetime(datetime_str)
                    except Exception as e:
                        raise ValueError(f"æ—¥æ™‚ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: '{datetime_str}'")
                    
                    # æ¸©åº¦å¤‰æ›
                    temperature = float(row['temperature'])
                    
                    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                    skin_data = SkinTemperatureData(
                        halshare_id=sensor_id,
                        datetime=parsed_datetime,
                        temperature=temperature,
                        upload_batch_id=batch_id,
                        competition_id=competition_id
                    )
                    db.add(skin_data)
                    success_count += 1
                    
                except Exception as e:
                    failed_count += 1
                    print(f"è¡Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒãƒƒãƒæƒ…å ±æ›´æ–°
            batch.total_records = len(df)
            batch.success_records = success_count
            batch.failed_records = failed_count
            batch.status = UploadStatus.SUCCESS if failed_count == 0 else UploadStatus.PARTIAL
            
            db.commit()
            
            results.append({
                "file": file.filename,
                "batch_id": batch_id,
                "total": len(df),
                "success": success_count,
                "failed": failed_count,
                "status": batch.status.value
            })
            
        except Exception as e:
            db.rollback()
            results.append({
                "file": file.filename,
                "error": str(e),
                "status": "failed"
            })
    
    return {"results": results}


@router.post("/upload/core-temperature")
async def upload_core_temperature(
    competition_id: str = Form(...),
    files: List[UploadFile] = File(...),
    db: Session = Depends(get_db),
    current_admin: AdminUser = Depends(get_current_admin)
):
    """ã‚«ãƒ—ã‚»ãƒ«ä½“æ¸©ãƒ‡ãƒ¼ã‚¿ï¼ˆe-Celciusï¼‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ - å…ƒã®admin.pyæ–¹å¼"""
    
    competition = db.query(Competition).filter_by(competition_id=competition_id).first()
    if not competition:
        raise HTTPException(status_code=404, detail="Competition not found")
    
    results = []
    
    for file in files:
        batch_id = generate_batch_id(file.filename)
        
        try:
            content = await file.read()
            encoding = detect_encoding(content)
            
            text_content = content.decode(encoding)
            lines = text_content.splitlines()
            
            # ã‚»ãƒ³ã‚µãƒ¼IDã‚’5è¡Œç›®ã‹ã‚‰æŠ½å‡º
            sensor_ids = {}
            if len(lines) > 4:
                header_line = lines[4]
                parts = header_line.split(',')
                
                for i, part in enumerate(parts):
                    if 'Pill' in part and i + 1 < len(parts):
                        sensor_id = parts[i + 1].strip()
                        if sensor_id:
                            sensor_ids[i] = sensor_id
            
            # UploadBatchä½œæˆ
            from app.models.flexible_sensor_data import UploadBatch, SensorType, UploadStatus, CoreTemperatureData
            batch = UploadBatch(
                batch_id=batch_id,
                sensor_type=SensorType.CORE_TEMPERATURE,
                file_name=file.filename,
                competition_id=competition_id,
            )
            db.add(batch)
            
            success_count = 0
            failed_count = 0
            
            # 6è¡Œç›®ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
            for line_num, line in enumerate(lines[6:], start=7):
                line = line.strip()
                if not line:
                    continue
                
                # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if any(msg in line.upper() for msg in ['CRITICAL', 'LOW BATTERY', 'MONITOR WAKE-UP', 'SYSTEM']):
                    continue
                    
                parts = line.split(',')
                
                if len(parts) < 15:
                    continue
                
                # 3ã¤ã®ã‚»ãƒ³ã‚µãƒ¼åˆ—ã‚’å‡¦ç†ï¼ˆ0, 7, 14åˆ—ç›®ï¼‰
                sensor_columns = [0, 7, 14]
                for sensor_col in sensor_columns:
                    if sensor_col in sensor_ids and sensor_col + 4 < len(parts):
                        try:
                            date_str = parts[sensor_col + 1].strip()
                            hour_str = parts[sensor_col + 2].strip()
                            temp_str = parts[sensor_col + 3].strip()
                            status_str = parts[sensor_col + 4].strip()
                            
                            if temp_str and temp_str != '---':
                                datetime_obj = pd.to_datetime(f"{date_str} {hour_str}")
                                temperature = float(temp_str)
                                
                                core_data = CoreTemperatureData(
                                    capsule_id=sensor_ids[sensor_col],
                                    monitor_id=f"monitor_{sensor_col}",
                                    datetime=datetime_obj,
                                    temperature=temperature,
                                    status=status_str,
                                    upload_batch_id=batch_id,
                                    competition_id=competition_id
                                )
                                db.add(core_data)
                                success_count += 1
                                
                        except Exception as e:
                            failed_count += 1
                            print(f"è¡Œ{line_num}ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒãƒƒãƒæƒ…å ±æ›´æ–°
            batch.total_records = success_count + failed_count
            batch.success_records = success_count
            batch.failed_records = failed_count
            batch.status = UploadStatus.SUCCESS if failed_count == 0 else UploadStatus.PARTIAL
            
            db.commit()
            
            results.append({
                "file": file.filename,
                "batch_id": batch_id,
                "total": success_count + failed_count,
                "success": success_count,
                "failed": failed_count,
                "status": batch.status.value
            })
            
        except Exception as e:
            db.rollback()
            results.append({
                "file": file.filename,
                "error": str(e),
                "status": "failed"
            })
    
    return {"results": results}


@router.post("/upload/heart-rate")
async def upload_heart_rate(
    competition_id: str = Form(...),
    sensor_id: str = Form(...),
    files: List[UploadFile] = File(...),
    db: Session = Depends(get_db),
    current_admin: AdminUser = Depends(get_current_admin)
):
    """å¿ƒæ‹ãƒ‡ãƒ¼ã‚¿ï¼ˆTCX/XMLï¼‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ - å…ƒã®admin.pyæ–¹å¼"""
    
    competition = db.query(Competition).filter_by(competition_id=competition_id).first()
    if not competition:
        raise HTTPException(status_code=404, detail="Competition not found")
    
    results = []
    
    for file in files:
        batch_id = generate_batch_id(file.filename)
        
        try:
            content = await file.read()
            
            # XMLè§£æ
            try:
                root = ET.fromstring(content)
            except ET.ParseError as e:
                results.append({
                    "file": file.filename,
                    "error": f"XMLè§£æã‚¨ãƒ©ãƒ¼: {str(e)}",
                    "status": "failed"
                })
                continue
            
            # UploadBatchä½œæˆ
            from app.models.flexible_sensor_data import UploadBatch, SensorType, UploadStatus, HeartRateData
            batch = UploadBatch(
                batch_id=batch_id,
                sensor_type=SensorType.HEART_RATE,
                file_name=file.filename,
                competition_id=competition_id,
            )
            db.add(batch)
            
            success_count = 0
            failed_count = 0
            
            # TCXåå‰ç©ºé–“
            namespaces = {
                'tcx': 'http://www.garmin.com/xmlschemas/TrainingCenterDatabase/v2'
            }
            
            
            # TrackPointãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            trackpoints = root.findall('.//tcx:Trackpoint', namespaces)
            
            for trackpoint in trackpoints:
                try:
                    # æ™‚åˆ»
                    time_elem = trackpoint.find('tcx:Time', namespaces)
                    if time_elem is None:
                        continue
                    
                    time_str = time_elem.text
                    time_obj = pd.to_datetime(time_str)
                    
                    # å¿ƒæ‹æ•°
                    hr_elem = trackpoint.find('.//tcx:HeartRateBpm/tcx:Value', namespaces)
                    if hr_elem is None:
                        continue
                    
                    heart_rate = int(hr_elem.text)
                    
                    # HeartRateDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
                    hr_data = HeartRateData(
                        sensor_id=sensor_id,
                        time=time_obj,
                        heart_rate=heart_rate,
                        upload_batch_id=batch_id,
                        competition_id=competition_id
                    )
                    db.add(hr_data)
                    success_count += 1
                    
                except Exception as e:
                    failed_count += 1
                    print(f"TrackPointå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒãƒƒãƒæƒ…å ±æ›´æ–°
            batch.total_records = success_count + failed_count
            batch.success_records = success_count
            batch.failed_records = failed_count
            batch.status = UploadStatus.SUCCESS if failed_count == 0 else UploadStatus.PARTIAL
            
            db.commit()
            print("================================")
            results.append({
                "file": file.filename,
                "batch_id": batch_id,
                "total": success_count + failed_count,
                "success": success_count,
                "failed": failed_count,
                "status": batch.status.value
            })
            print("|||||||||||||||||||||||||||||||")
            print(batch.status.value)
        except Exception as e:
            db.rollback()
            results.append({
                "file": file.filename,
                "error": str(e),
                "status": "failed"
            })
    
    return {"results": results}


@router.post("/upload/wbgt")
async def upload_wbgt_data(
    competition_id: str = Form(...),
    wbgt_file: UploadFile = File(...),
    overwrite: bool = Form(True),
    db: Session = Depends(get_db),
    current_admin: AdminUser = Depends(get_current_admin)
):
    """WBGTç’°å¢ƒãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ - å…ƒã®admin.pyæ–¹å¼"""
    
    if not wbgt_file.filename.lower().endswith('.csv'):
        raise HTTPException(status_code=400, detail="CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™")
    
    competition = db.query(Competition).filter_by(competition_id=competition_id).first()
    if not competition:
        raise HTTPException(status_code=400, detail=f"å¤§ä¼šID '{competition_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    try:
        # ä¸Šæ›¸ãå‡¦ç†ï¼šæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
        if overwrite:
            from app.models.flexible_sensor_data import WBGTData
            deleted_count = db.query(WBGTData).filter_by(competition_id=competition_id).delete()
            db.commit()
            print(f"æ—¢å­˜WBGTãƒ‡ãƒ¼ã‚¿{deleted_count}ä»¶ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        content = await wbgt_file.read()
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºãƒ»èª­ã¿è¾¼ã¿
        encoding = detect_encoding(content)
        try:
            decoded_content = content.decode(encoding)
        except UnicodeDecodeError:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šShift_JISï¼ˆæ—¥æœ¬ã®æ©Ÿå™¨ï¼‰
            try:
                decoded_content = content.decode('shift_jis')
            except UnicodeDecodeError:
                decoded_content = content.decode('utf-8', errors='replace')
        
        # CSVãƒ‘ãƒ¼ã‚¹
        df = pd.read_csv(io.StringIO(decoded_content))
        
        # åˆ—åãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ—¥æœ¬èªãƒ»è‹±èªä¸¡å¯¾å¿œï¼‰
        column_mapping = {
            'date': None,
            'time': None,
            'wbgt': None,
            'air_temperature': None,
            'humidity': None,
            'globe_temperature': None
        }
        
        # åˆ—åã‚’æ­£è¦åŒ–ã—ã¦æ¤œç´¢
        for col in df.columns:
            col_clean = str(col).strip().lower()
            if 'æ—¥ä»˜' in col or 'date' in col_clean:
                column_mapping['date'] = col
            elif 'æ™‚åˆ»' in col or 'time' in col_clean:
                column_mapping['time'] = col
            elif 'wbgt' in col_clean:
                column_mapping['wbgt'] = col
            elif 'æ°—æ¸©' in col or 'air' in col_clean:
                column_mapping['air_temperature'] = col
            elif 'æ¹¿åº¦' in col or 'humidity' in col_clean:
                column_mapping['humidity'] = col
            elif 'é»’çƒ' in col or 'globe' in col_clean:
                column_mapping['globe_temperature'] = col
        
        # å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
        if not column_mapping['date'] or not column_mapping['time'] or not column_mapping['wbgt']:
            raise HTTPException(
                status_code=400,
                detail=f"å¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç¾åœ¨ã®åˆ—: {list(df.columns)}"
            )
        
        # ãƒãƒƒãƒIDç”Ÿæˆ
        batch_id = generate_batch_id(wbgt_file.filename)
        
        # UploadBatchä½œæˆ
        from app.models.flexible_sensor_data import UploadBatch, SensorType, UploadStatus, WBGTData
        batch = UploadBatch(
            batch_id=batch_id,
            sensor_type=SensorType.WBGT,
            file_name=wbgt_file.filename,
            competition_id=competition_id,
        )
        db.add(batch)
        
        success_count = 0
        failed_count = 0
        
        # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        for index, row in df.iterrows():
            try:
                # æ—¥ä»˜ã¨æ™‚åˆ»ã®çµåˆ
                date_str = str(row[column_mapping['date']]).strip()
                time_str = str(row[column_mapping['time']]).strip()
                
                if pd.isna(row[column_mapping['date']]) or pd.isna(row[column_mapping['time']]):
                    failed_count += 1
                    continue
                
                # æ—¥æ™‚ãƒ‘ãƒ¼ã‚¹
                datetime_str = f"{date_str} {time_str}"
                datetime_obj = pd.to_datetime(datetime_str)
                
                # WBGTå€¤å–å¾—
                wbgt_value = float(row[column_mapping['wbgt']])
                
                # ã‚ªãƒ—ã‚·ãƒ§ãƒ³å€¤å–å¾—
                air_temp = None
                humidity = None
                globe_temp = None
                
                if column_mapping['air_temperature']:
                    try:
                        air_temp = float(row[column_mapping['air_temperature']])
                    except (ValueError, TypeError):
                        pass
                
                if column_mapping['humidity']:
                    try:
                        humidity = float(row[column_mapping['humidity']])
                    except (ValueError, TypeError):
                        pass
                
                if column_mapping['globe_temperature']:
                    try:
                        globe_temp = float(row[column_mapping['globe_temperature']])
                    except (ValueError, TypeError):
                        pass
                
                # WBGTDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
                wbgt_data = WBGTData(
                    timestamp=datetime_obj,
                    wbgt_value=wbgt_value,
                    air_temperature=air_temp,
                    humidity=humidity,
                    globe_temperature=globe_temp,
                    competition_id=competition_id,
                    upload_batch_id=batch_id
                )
                db.add(wbgt_data)
                success_count += 1
                
            except Exception as e:
                failed_count += 1
                print(f"è¡Œ{index+1}å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒãƒƒãƒæƒ…å ±æ›´æ–°
        batch.total_records = success_count + failed_count
        batch.success_records = success_count
        batch.failed_records = failed_count
        batch.status = UploadStatus.SUCCESS if failed_count == 0 else UploadStatus.PARTIAL
        
        db.commit()
        
        return {
            "success": success_count > 0,
            "message": f"WBGTç’°å¢ƒãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†",
            "total_records": success_count + failed_count,
            "processed_records": success_count,
            "failed_records": failed_count,
            "batch_id": batch_id
        }
        
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"WBGTã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {str(e)}")


@router.post("/upload/race-records")
async def upload_race_records(
    competition_id: str = Form(...),
    files: List[UploadFile] = File(...),
    overwrite: bool = Form(True),
    db: Session = Depends(get_db),
    current_admin: AdminUser = Depends(get_current_admin)
):
    """å¤§ä¼šè¨˜éŒ²ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ - å…ƒã®admin.pyæ–¹å¼"""
    
    competition = db.query(Competition).filter_by(competition_id=competition_id).first()
    if not competition:
        raise HTTPException(status_code=404, detail="å¤§ä¼šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    try:
        # ä¸Šæ›¸ãå‡¦ç†ï¼šæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
        if overwrite:
            from app.models.competition import RaceRecord
            deleted_count = db.query(RaceRecord).filter_by(competition_id=competition_id).delete()
            db.commit()
            print(f"æ—¢å­˜å¤§ä¼šè¨˜éŒ²ãƒ‡ãƒ¼ã‚¿{deleted_count}ä»¶ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        
        total_csv_records = 0
        saved_records = 0
        failed_records = 0
        errors = []
        
        for file in files:
            if not file.filename.endswith('.csv'):
                errors.append(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file.filename}' ã¯CSVã§ã¯ã‚ã‚Šã¾ã›ã‚“")
                continue
            
            try:
                # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
                content = await file.read()
                encoding = detect_encoding(content)
                
                try:
                    df = pd.read_csv(io.BytesIO(content), encoding=encoding)
                except UnicodeDecodeError:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                    for fallback_encoding in ['utf-8', 'shift_jis', 'cp932']:
                        try:
                            df = pd.read_csv(io.BytesIO(content), encoding=fallback_encoding)
                            break
                        except UnicodeDecodeError:
                            continue
                    else:
                        errors.append(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file.filename}' ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                        continue
                
                print(f"ğŸ“Š {file.filename}: {len(df)}è¡Œ, åˆ—: {list(df.columns)}")
                
                # åˆ—åã®ç©ºç™½é™¤å»
                df.columns = df.columns.str.strip()
                
                # ã‚¼ãƒƒã‚±ãƒ³ç•ªå·åˆ—ã®æ¤œç´¢
                bib_number_col = None
                for col in df.columns:
                    if any(keyword in str(col).lower() for keyword in ['no.', 'no', 'ã‚¼ãƒƒã‚±ãƒ³', 'bib', 'ç•ªå·']):
                        bib_number_col = col
                        break
                
                if not bib_number_col:
                    errors.append(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file.filename}' ã«ã‚¼ãƒƒã‚±ãƒ³ç•ªå·åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    continue
                
                # èªè­˜å¯èƒ½ãªåˆ—ãƒãƒƒãƒ”ãƒ³ã‚°
                column_mapping = {
                    'swim_start': None,
                    'swim_finish': None,
                    'bike_start': None,
                    'bike_finish': None,
                    'run_start': None,
                    'run_finish': None
                }
                
                # LAPåˆ—ã®æ¤œç´¢
                lap_columns = []
                
                for col in df.columns:
                    col_lower = str(col).lower()
                    if 'swim' in col_lower and 'start' in col_lower:
                        column_mapping['swim_start'] = col
                    elif 'swim' in col_lower and ('finish' in col_lower or 'end' in col_lower):
                        column_mapping['swim_finish'] = col
                    elif 'bike' in col_lower and 'start' in col_lower:
                        column_mapping['bike_start'] = col
                    elif 'bike' in col_lower and ('finish' in col_lower or 'end' in col_lower):
                        column_mapping['bike_finish'] = col
                    elif 'run' in col_lower and 'start' in col_lower:
                        column_mapping['run_start'] = col
                    elif 'run' in col_lower and ('finish' in col_lower or 'end' in col_lower):
                        column_mapping['run_finish'] = col
                    elif any(lap_keyword in col_lower for lap_keyword in ['lap', 'bl', 'checkpoint']):
                        lap_columns.append(col)
                
                # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
                file_records = 0
                for index, row in df.iterrows():
                    try:
                        # ã‚¼ãƒƒã‚±ãƒ³ç•ªå·å–å¾—
                        bib_number = str(row[bib_number_col]).strip()
                        if not bib_number or bib_number == 'nan':
                            continue
                        
                        # æ™‚åˆ»ãƒ‡ãƒ¼ã‚¿ã®è§£æ
                        def parse_time(time_str):
                            if pd.isna(time_str) or str(time_str).strip() == '':
                                return None
                            try:
                                return pd.to_datetime(str(time_str).strip())
                            except:
                                return None
                        
                        # åŸºæœ¬ç«¶æŠ€æ™‚åˆ»
                        swim_start = parse_time(row.get(column_mapping['swim_start']))
                        swim_finish = parse_time(row.get(column_mapping['swim_finish']))
                        bike_start = parse_time(row.get(column_mapping['bike_start']))
                        bike_finish = parse_time(row.get(column_mapping['bike_finish']))
                        run_start = parse_time(row.get(column_mapping['run_start']))
                        run_finish = parse_time(row.get(column_mapping['run_finish']))
                        
                        # LAPæ™‚åˆ»ãƒ‡ãƒ¼ã‚¿åé›†
                        lap_times = {}
                        for lap_col in lap_columns:
                            lap_time = parse_time(row.get(lap_col))
                            if lap_time:
                                lap_times[lap_col] = lap_time.isoformat()
                        
                        # RaceRecordã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
                        from app.models.competition import RaceRecord
                        race_record = RaceRecord(
                            competition_id=competition_id,
                            race_number=bib_number,  # ã‚¼ãƒƒã‚±ãƒ³ç•ªå·
                            user_id=None,  # ãƒãƒƒãƒ”ãƒ³ã‚°å‰ã¯ç©º
                            swim_start=swim_start,
                            swim_finish=swim_finish,
                            bike_start=bike_start,
                            bike_finish=bike_finish,
                            run_start=run_start,
                            run_finish=run_finish,
                            lap_times=lap_times if lap_times else None,
                            source_file=file.filename
                        )
                        
                        db.add(race_record)
                        file_records += 1
                        saved_records += 1
                        
                    except Exception as e:
                        failed_records += 1
                        errors.append(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file.filename}' è¡Œ{index+1}: {str(e)}")
                
                total_csv_records += len(df)
                print(f"âœ… {file.filename}: {file_records}ä»¶ä¿å­˜")
                
            except Exception as e:
                errors.append(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file.filename}' å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        db.commit()
        
        return {
            "success": saved_records > 0,
            "message": f"å¤§ä¼šè¨˜éŒ²ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {saved_records}ä»¶ä¿å­˜",
            "total_csv_records": total_csv_records,
            "saved_records": saved_records,
            "failed_records": failed_records,
            "errors": errors
        }
        
    except Exception as e:
        db.rollback()
        raise HTTPException(
            status_code=500,
            detail=f"å¤§ä¼šè¨˜éŒ²ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}"
        )


@router.post("/upload/mapping")
async def upload_mapping_data(
    mapping_file: UploadFile = File(...),
    competition_id: str = Form(...),
    overwrite: bool = Form(True),
    db: Session = Depends(get_db),
    current_admin: AdminUser = Depends(get_current_admin)
):
    """ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ - å…ƒã®admin.pyæ–¹å¼"""
    
    if not mapping_file.filename.lower().endswith('.csv'):
        raise HTTPException(status_code=400, detail="CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™")
    
    competition = db.query(Competition).filter_by(competition_id=competition_id).first()
    if not competition:
        raise HTTPException(status_code=400, detail=f"å¤§ä¼šID '{competition_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    try:
        # ä¸Šæ›¸ãå‡¦ç†ï¼šæ—¢å­˜ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å‰Šé™¤
        if overwrite:
            from app.models.flexible_sensor_data import FlexibleSensorMapping
            existing_count = db.query(FlexibleSensorMapping).filter_by(competition_id=competition_id).delete()
            db.commit()
            print(f"æ—¢å­˜ãƒãƒƒãƒ”ãƒ³ã‚°å‰Šé™¤: {existing_count}ä»¶")
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        content = await mapping_file.read()
        encoding = detect_encoding(content)
        
        try:
            df = pd.read_csv(io.BytesIO(content), encoding=encoding)
        except UnicodeDecodeError:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            for fallback_encoding in ['utf-8', 'shift_jis', 'cp932']:
                try:
                    df = pd.read_csv(io.BytesIO(content), encoding=fallback_encoding)
                    break
                except UnicodeDecodeError:
                    continue
            else:
                raise HTTPException(status_code=400, detail="CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
        
        if df.empty:
            raise HTTPException(status_code=400, detail="CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")
        
        # åˆ—åã®ç©ºç™½é™¤å»
        df.columns = df.columns.str.strip()
        
        # å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
        if 'user_id' not in df.columns:
            raise HTTPException(status_code=400, detail="user_idåˆ—ãŒå¿…è¦ã§ã™")
        
        # èªè­˜ã™ã‚‹ã‚»ãƒ³ã‚µãƒ¼åˆ—
        sensor_column_mapping = {
            'skin_temp_sensor_id': 'skin_temperature_sensor_id',
            'core_temp_sensor_id': 'core_temperature_sensor_id',
            'heart_rate_sensor_id': 'heart_rate_sensor_id',
            'skin_temperature_sensor_id': 'skin_temperature_sensor_id',
            'core_temperature_sensor_id': 'core_temperature_sensor_id',
            'heart_rate_id': 'heart_rate_sensor_id',
        }
        
        # å¤§ä¼šè¨˜éŒ²åˆ—
        race_number_col = None
        for col in df.columns:
            if any(keyword in str(col).lower() for keyword in ['race_number', 'ã‚¼ãƒƒã‚±ãƒ³', 'bib', 'no']):
                race_number_col = col
                break
        
        processed = 0
        skipped = 0
        errors = []
        race_number_mappings = 0
        
        for index, row in df.iterrows():
            try:
                user_id = str(row.get('user_id', '')).strip()
                
                if not user_id or user_id == 'nan':
                    skipped += 1
                    continue
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼å­˜åœ¨ãƒã‚§ãƒƒã‚¯
                from app.models.user import User
                user = db.query(User).filter_by(user_id=user_id).first()
                if not user:
                    errors.append(f"è¡Œ{index+1}: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID '{user_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    skipped += 1
                    continue
                
                # ã‚»ãƒ³ã‚µãƒ¼IDã®åé›†
                sensor_data = {}
                for csv_col, mapped_col in sensor_column_mapping.items():
                    if csv_col in df.columns:
                        sensor_id = str(row.get(csv_col, '')).strip()
                        if sensor_id and sensor_id != 'nan':
                            sensor_data[mapped_col] = sensor_id
                
                # ã‚¼ãƒƒã‚±ãƒ³ç•ªå·ã®å‡¦ç†
                race_number = None
                if race_number_col and race_number_col in df.columns:
                    race_num_value = str(row.get(race_number_col, '')).strip()
                    if race_num_value and race_num_value != 'nan':
                        race_number = race_num_value
                
                # ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆ
                from app.models.flexible_sensor_data import FlexibleSensorMapping
                mapping = FlexibleSensorMapping(
                    user_id=user_id,
                    competition_id=competition_id,
                    skin_temperature_sensor_id=sensor_data.get('skin_temperature_sensor_id'),
                    core_temperature_sensor_id=sensor_data.get('core_temperature_sensor_id'),
                    heart_rate_sensor_id=sensor_data.get('heart_rate_sensor_id'),
                    race_number=race_number
                )
                
                db.add(mapping)
                processed += 1
                
                # å¤§ä¼šè¨˜éŒ²ã«user_idã‚’é©ç”¨
                if race_number:
                    from app.models.competition import RaceRecord
                    race_records = db.query(RaceRecord).filter_by(
                        competition_id=competition_id,
                        race_number=race_number
                    ).all()
                    
                    for record in race_records:
                        record.user_id = user_id
                        race_number_mappings += 1
                
            except Exception as e:
                errors.append(f"è¡Œ{index+1}: {str(e)}")
                skipped += 1
        
        db.commit()
        
        return {
            "success": processed > 0,
            "message": f"ãƒãƒƒãƒ”ãƒ³ã‚°å‡¦ç†å®Œäº†: {processed}ä»¶ä½œæˆ",
            "total_records": len(df),
            "processed_records": processed,
            "skipped_records": skipped,
            "race_number_mappings": race_number_mappings,
            "errors": errors
        }
        
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"ãƒãƒƒãƒ”ãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {str(e)}")

# data_uploads.py ã«è¿½åŠ ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

@router.get("/race-records/status")
async def get_race_records_status(
    competition_id: str = Query(None),
    db: Session = Depends(get_db),
    current_admin: AdminUser = Depends(get_current_admin)
):
    """å¤§ä¼šè¨˜éŒ²ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çŠ¶æ³å–å¾—"""
    
    try:
        # ã‚¯ã‚¨ãƒªæ§‹ç¯‰
        from app.models.competition import RaceRecord
        query = db.query(RaceRecord)
        if competition_id:
            query = query.filter_by(competition_id=competition_id)
        
        records = query.all()
        
        # çµ±è¨ˆè¨ˆç®—
        total_records = len(records)
        mapped_records = len([r for r in records if r.user_id is not None])
        unmapped_records = total_records - mapped_records
        
        # å¤§ä¼šåˆ¥çµ±è¨ˆ
        by_competition = {}
        for record in records:
            comp_id = record.competition_id
            if comp_id not in by_competition:
                competition = db.query(Competition).filter_by(competition_id=comp_id).first()
                by_competition[comp_id] = {
                    "competition_name": competition.name if competition else "Unknown",
                    "total_records": 0,
                    "mapped_records": 0,
                    "unmapped_records": 0,
                    "latest_upload": None
                }
            
            by_competition[comp_id]["total_records"] += 1
            if record.user_id:
                by_competition[comp_id]["mapped_records"] += 1
            else:
                by_competition[comp_id]["unmapped_records"] += 1
            
            # æœ€æ–°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚åˆ»ï¼ˆcreated_atãŒã‚ã‚‹å ´åˆï¼‰
            if hasattr(record, 'created_at') and record.created_at:
                current_latest = by_competition[comp_id]["latest_upload"]
                record_time_str = record.created_at.isoformat()
                if current_latest is None or record_time_str > current_latest:
                    by_competition[comp_id]["latest_upload"] = record_time_str
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹ç¯‰
        return {
            "success": True,
            "total_records": total_records,
            "mapped_records": mapped_records,
            "unmapped_records": unmapped_records,
            "mapping_coverage": round((mapped_records / total_records * 100), 2) if total_records > 0 else 0,
            "competitions": by_competition,
            "competition_count": len(by_competition)
        }
        
    except Exception as e:
        error_message = f"å¤§ä¼šè¨˜éŒ²çŠ¶æ³å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        print(f"âŒ {error_message}")
        raise HTTPException(status_code=500, detail=error_message)


@router.get("/race-records/details")
async def get_race_records_details(
    competition_id: str = Query(...),
    db: Session = Depends(get_db),
    current_admin: AdminUser = Depends(get_current_admin)
):
    """å¤§ä¼šè¨˜éŒ²è©³ç´°æƒ…å ±å–å¾—"""
    
    try:
        # å¤§ä¼šå­˜åœ¨ãƒã‚§ãƒƒã‚¯
        competition = db.query(Competition).filter_by(competition_id=competition_id).first()
        if not competition:
            raise HTTPException(status_code=404, detail="Competition not found")
        
        # å¤§ä¼šè¨˜éŒ²å–å¾—
        from app.models.competition import RaceRecord
        records = db.query(RaceRecord).filter_by(competition_id=competition_id).all()
        
        race_details = []
        for record in records:
            # ç«¶æŠ€æ™‚é–“è¨ˆç®—
            swim_duration = None
            bike_duration = None
            run_duration = None
            total_duration = None
            
            if record.swim_start and record.swim_finish:
                swim_duration = (record.swim_finish - record.swim_start).total_seconds()
            
            if record.bike_start and record.bike_finish:
                bike_duration = (record.bike_finish - record.bike_start).total_seconds()
            
            if record.run_start and record.run_finish:
                run_duration = (record.run_finish - record.run_start).total_seconds()
            
            # å…¨ä½“æ™‚é–“ã®è¨ˆç®—
            if record.swim_start and record.run_finish:
                total_duration = (record.run_finish - record.swim_start).total_seconds()
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å–å¾—
            user_info = None
            if record.user_id:
                from app.models.user import User
                user = db.query(User).filter_by(user_id=record.user_id).first()
                if user:
                    user_info = {
                        "user_id": user.user_id,
                        "full_name": user.full_name,
                        "email": user.email
                    }
            
            race_details.append({
                "id": record.id,
                "race_number": record.race_number,
                "user_id": record.user_id,
                "user_info": user_info,
                "is_mapped": record.user_id is not None,
                "swim_start": record.swim_start.isoformat() if record.swim_start else None,
                "swim_finish": record.swim_finish.isoformat() if record.swim_finish else None,
                "bike_start": record.bike_start.isoformat() if record.bike_start else None,
                "bike_finish": record.bike_finish.isoformat() if record.bike_finish else None,
                "run_start": record.run_start.isoformat() if record.run_start else None,
                "run_finish": record.run_finish.isoformat() if record.run_finish else None,
                "swim_duration_seconds": swim_duration,
                "bike_duration_seconds": bike_duration,
                "run_duration_seconds": run_duration,
                "total_duration_seconds": total_duration,
                "lap_times": record.lap_times,  # JSONå½¢å¼ã®LAPãƒ‡ãƒ¼ã‚¿
                "source_file": record.source_file,
                "created_at": record.created_at.isoformat() if hasattr(record, 'created_at') and record.created_at else None
            })
        
        return {
            "success": True,
            "competition_id": competition_id,
            "competition_name": competition.name,
            "total_records": len(records),
            "records": race_details
        }
        
    except Exception as e:
        error_message = f"å¤§ä¼šè¨˜éŒ²è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        print(f"âŒ {error_message}")
        raise HTTPException(status_code=500, detail=error_message)


@router.delete("/race-records/{competition_id}")
async def delete_race_records(
    competition_id: str,
    db: Session = Depends(get_db),
    current_admin: AdminUser = Depends(get_current_admin)
):
    """å¤§ä¼šè¨˜éŒ²å‰Šé™¤"""
    
    try:
        # å¤§ä¼šå­˜åœ¨ãƒã‚§ãƒƒã‚¯
        competition = db.query(Competition).filter_by(competition_id=competition_id).first()
        if not competition:
            raise HTTPException(status_code=404, detail="Competition not found")
        
        # å‰Šé™¤å®Ÿè¡Œ
        from app.models.competition import RaceRecord
        deleted_count = db.query(RaceRecord).filter_by(competition_id=competition_id).delete()
        db.commit()
        
        return {
            "success": True,
            "message": f"å¤§ä¼š'{competition.name}'ã®è¨˜éŒ²{deleted_count}ä»¶ã‚’å‰Šé™¤ã—ã¾ã—ãŸ",
            "deleted_records": deleted_count,
            "competition_id": competition_id
        }
        
    except Exception as e:
        db.rollback()
        error_message = f"å¤§ä¼šè¨˜éŒ²å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}"
        print(f"âŒ {error_message}")
        raise HTTPException(status_code=500, detail=error_message)
