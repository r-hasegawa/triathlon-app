"""
app/services/flexible_csv_service.py

å®Ÿãƒ‡ãƒ¼ã‚¿å¯¾å¿œç‰ˆï¼ˆWBGTå®Ÿè£…å«ã‚€ï¼‰
"""

import pandas as pd
import io
from fastapi import UploadFile, HTTPException
from sqlalchemy.orm import Session
from typing import Optional, Dict, Any, List
from datetime import datetime
from app.models.flexible_sensor_data import (
    RawSensorData, FlexibleSensorMapping,
    SkinTemperatureData, CoreTemperatureData, 
    HeartRateData, WBGTData, SensorDataStatus, SensorType
)
from app.schemas.sensor_data import (
    UploadResponse, MappingResponse,
    DataSummaryResponse, MappingStatusResponse
)

class FlexibleCSVService:
    
    async def process_sensor_data_only(
        self,
        sensor_file: UploadFile,
        sensor_type: SensorType,
        competition_id: str,
        db: Session
    ) -> UploadResponse:
        """ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ã¿å‡¦ç†"""
        try:
            # å¤§ä¼šå­˜åœ¨ãƒã‚§ãƒƒã‚¯è¿½åŠ 
            from app.models import Competition
            competition = db.query(Competition).filter_by(competition_id=competition_id).first()
            if not competition:
                raise HTTPException(status_code=400, detail=f"å¤§ä¼šID '{competition_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            content = await sensor_file.read()
            df = pd.read_csv(io.BytesIO(content))
            
            processed = 0
            
            for _, row in df.iterrows():
                raw_data = RawSensorData(
                    sensor_type=sensor_type,
                    sensor_id=str(row.get('sensor_id', '')),
                    timestamp=pd.to_datetime(row.get('timestamp')),
                    data_values=str(row.get('value', 0)),
                    competition_id=competition_id,
                    mapping_status=SensorDataStatus.UNMAPPED,
                    raw_data=row.to_json()
                )
                db.add(raw_data)
                processed += 1
            
            db.commit()
            
            return UploadResponse(
                success=True,
                message=f"{sensor_type.value}ãƒ‡ãƒ¼ã‚¿ã‚’{processed}ä»¶å‡¦ç†ã—ã¾ã—ãŸï¼ˆå¤§ä¼š: {competition.name}ï¼‰",
                total_records=len(df),
                processed_records=processed
            )
            
        except Exception as e:
            db.rollback()
            raise HTTPException(status_code=400, detail=f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")

    async def process_wbgt_data(
        self,
        wbgt_file: UploadFile,
        competition_id: Optional[str],
        db: Session,
        overwrite: bool = True
    ) -> UploadResponse:
        """WBGTç’°å¢ƒãƒ‡ãƒ¼ã‚¿å‡¦ç†ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿å¯¾å¿œç‰ˆ + ãƒãƒƒãƒç®¡ç†ï¼‰
        
        ä»•æ§˜ï¼š
        - å…¥åŠ›ï¼šæ—¥ä»˜ã€æ™‚åˆ»ã€WBGTå€¤ã€æ°—æ¸©ã€ç›¸å¯¾æ¹¿åº¦ã€é»’çƒæ¸©åº¦ï¼ˆ6åˆ—ï¼‰
        - å‡¦ç†ï¼šæ—¥ä»˜ã¨æ™‚åˆ»ã‚’çµ„ã¿åˆã‚ã›ã¦ä¸€ã¤ã®datetimeã«å¤‰æ›
        - ä¿å­˜ï¼šdatetimeã€WBGTå€¤ã€æ°—æ¸©ã€ç›¸å¯¾æ¹¿åº¦ã€é»’çƒæ¸©åº¦ã®5ã¤ã®å€¤
        - ãƒãƒƒãƒç®¡ç†ï¼šä»–ã®ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã¨åŒæ§˜ã®ãƒãƒƒãƒç®¡ç†
        """
        try:
            # ãƒãƒƒãƒIDç”Ÿæˆ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            batch_id = f"{timestamp}_{wbgt_file.filename}"
            
            # ä¸Šæ›¸ãå‡¦ç†ï¼šæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
            if overwrite and competition_id:
                deleted_count = db.query(WBGTData).filter_by(competition_id=competition_id).delete()
                db.commit()
                print(f"æ—¢å­˜WBGTãƒ‡ãƒ¼ã‚¿{deleted_count}ä»¶ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œï¼‰
            content = await wbgt_file.read()
            
            # Shift_JISã§ç›´æ¥èª­ã¿è¾¼ã¿ï¼ˆWBGTãƒ‡ãƒ¼ã‚¿ã¯æ—¥æœ¬ã®æ©Ÿå™¨ãªã®ã§Shift_JISï¼‰
            try:
                decoded_content = content.decode('shift_jis')
                detected_encoding = 'shift_jis'
            except UnicodeDecodeError:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                for encoding in ['utf-8', 'cp932', 'iso-8859-1']:
                    try:
                        decoded_content = content.decode(encoding)
                        detected_encoding = encoding
                        break
                    except UnicodeDecodeError:
                        continue
                else:
                    raise HTTPException(status_code=400, detail="CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
            print(f"ä½¿ç”¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {detected_encoding}")
            
            # CSVã‚’DataFrameã«èª­ã¿è¾¼ã¿
            df = pd.read_csv(io.StringIO(decoded_content))
            
            print(f"èª­ã¿è¾¼ã¿å®Œäº† - è¡Œæ•°: {len(df)}, åˆ—æ•°: {len(df.columns)}")
            print(f"åˆ—å: {list(df.columns)}")
            
            # åˆ—åã®æ­£è¦åŒ–ï¼ˆæ–‡å­—åŒ–ã‘å¯¾å¿œï¼‰
            column_mapping = self._normalize_wbgt_columns(df.columns)
            
            if not column_mapping:
                raise HTTPException(
                    status_code=400, 
                    detail=f"WBGTå¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç¾åœ¨ã®åˆ—: {list(df.columns)}"
                )
            
            print(f"åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°: {column_mapping}")
            
            # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
            processed = 0
            errors = []
            
            for index, row in df.iterrows():
                try:
                    # æ—¥ä»˜ã¨æ™‚åˆ»ã®çµåˆ
                    datetime_value = self._combine_date_time(row, column_mapping)
                    
                    if datetime_value is None:
                        errors.append(f"è¡Œ{index+1}: æ—¥ä»˜ãƒ»æ™‚åˆ»ã®çµåˆã«å¤±æ•—")
                        continue
                    
                    # WBGTé–¢é€£ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
                    wbgt_value = self._safe_float(row.get(column_mapping.get('wbgt')))
                    air_temp = self._safe_float(row.get(column_mapping.get('air_temperature')))
                    humidity = self._safe_float(row.get(column_mapping.get('humidity')))
                    globe_temp = self._safe_float(row.get(column_mapping.get('globe_temperature')))
                    
                    # å¿…é ˆé …ç›®ãƒã‚§ãƒƒã‚¯
                    if wbgt_value is None:
                        errors.append(f"è¡Œ{index+1}: WBGTå€¤ãŒç„¡åŠ¹")
                        continue
                    
                    # WBGTDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆï¼ˆãƒãƒƒãƒç®¡ç†å¯¾å¿œï¼‰
                    wbgt_data = WBGTData(
                        timestamp=datetime_value,
                        wbgt_value=wbgt_value,
                        air_temperature=air_temp,
                        humidity=humidity,
                        globe_temperature=globe_temp,
                        competition_id=competition_id,
                        station_id="WBGT_STATION_001",  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                        upload_batch_id=batch_id,  # ğŸ†• ãƒãƒƒãƒIDè¨­å®š
                        uploaded_at=datetime.now()
                    )
                    
                    db.add(wbgt_data)
                    processed += 1
                    
                except Exception as e:
                    errors.append(f"è¡Œ{index+1}: {str(e)}")
                    continue
            
            # ğŸ†• UploadBatchè¨˜éŒ²ä½œæˆ
            from app.models.flexible_sensor_data import UploadBatch, UploadStatus, SensorType
            
            upload_batch = UploadBatch(
                batch_id=batch_id,
                sensor_type=SensorType.WBGT,  # WBGTç”¨ã®SensorType
                competition_id=competition_id,
                file_name=wbgt_file.filename,
                file_size=len(content),
                total_records=len(df),
                success_records=processed,
                failed_records=len(errors),
                status=UploadStatus.SUCCESS if len(errors) == 0 else UploadStatus.PARTIAL,
                uploaded_by="admin",  # TODO: å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã«å¤‰æ›´
                notes=f"ã‚¨ãƒ©ãƒ¼: {len(errors)}ä»¶" if errors else None
            )
            db.add(upload_batch)
            
            db.commit()
            
            # çµæœãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
            message = f"WBGTãƒ‡ãƒ¼ã‚¿ã‚’{processed}ä»¶å‡¦ç†ã—ã¾ã—ãŸï¼ˆãƒãƒƒãƒID: {batch_id}ï¼‰"
            if errors:
                message += f"ï¼ˆã‚¨ãƒ©ãƒ¼{len(errors)}ä»¶ï¼‰"
                print("ã‚¨ãƒ©ãƒ¼è©³ç´°:", errors[:10])  # æœ€åˆã®10ä»¶ã®ã¿ãƒ­ã‚°å‡ºåŠ›
            
            return UploadResponse(
                success=True,
                message=message,
                total_records=len(df),
                processed_records=processed,
                errors=errors[:20] if errors else []  # æœ€å¤§20ä»¶ã®ã‚¨ãƒ©ãƒ¼ã‚’è¿”å´
            )
            
        except Exception as e:
            db.rollback()
            raise HTTPException(status_code=400, detail=f"WBGTå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _normalize_wbgt_columns(self, columns: List[str]) -> Dict[str, str]:
        """WBGTåˆ—åã‚’æ­£è¦åŒ–ã—ã¦ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰"""
        columns = [str(col).strip() for col in columns]
        mapping = {}
        
        # å®Ÿãƒ‡ãƒ¼ã‚¿ã®æ­£ç¢ºãªåˆ—åã§ãƒãƒƒãƒ”ãƒ³ã‚°
        column_map = {
            'æ—¥ä»˜': 'date',
            'æ™‚åˆ»': 'time', 
            'WBGTå€¤': 'wbgt',
            'æ°—æ¸©': 'air_temperature',
            'ç›¸å¯¾æ¹¿åº¦': 'humidity',
            'é»’çƒæ¸©åº¦': 'globe_temperature'
        }
        
        # æ­£ç¢ºãªåˆ—åãƒãƒƒãƒãƒ³ã‚°
        for col in columns:
            if col in column_map:
                mapping[column_map[col]] = col
        
        # æœ€ä½é™WBGTå€¤ãŒå¿…è¦
        if 'wbgt' not in mapping:
            return {}
        
        return mapping

    def _combine_date_time(self, row: pd.Series, column_mapping: Dict[str, str]) -> Optional[datetime]:
        """æ—¥ä»˜ã¨æ™‚åˆ»ã‚’çµåˆã—ã¦datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰"""
        try:
            date_col = column_mapping.get('date')  # 'æ—¥ä»˜'
            time_col = column_mapping.get('time')  # 'æ™‚åˆ»'
            
            if not date_col or not time_col:
                return None
                
            date_str = str(row.get(date_col, '')).strip()  # '2025/07/15'
            time_str = str(row.get(time_col, '')).strip()  # '17:43:38'
            
            if not date_str or not time_str or date_str == 'nan' or time_str == 'nan':
                return None
            
            # å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: '2025/07/15 17:43:38'
            datetime_str = f"{date_str} {time_str}"
            
            try:
                # å®Ÿãƒ‡ãƒ¼ã‚¿ã®æ­£ç¢ºãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                return datetime.strptime(datetime_str, '%Y/%m/%d %H:%M:%S')
            except ValueError:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                try:
                    return pd.to_datetime(datetime_str)
                except:
                    return None
            
        except Exception as e:
            print(f"æ—¥ä»˜ãƒ»æ™‚åˆ»çµåˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _safe_float(self, value) -> Optional[float]:
        """å®‰å…¨ã«floatå¤‰æ›"""
        if value is None or pd.isna(value):
            return None
        
        try:
            return float(value)
        except (ValueError, TypeError):
            return None

    async def process_mapping_data(
        self,
        mapping_file: UploadFile,
        competition_id: str,  # å¿…é ˆ
        db: Session,
        overwrite: bool = True
    ) -> MappingResponse:
        """æŸ”è»Ÿãªãƒãƒƒãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
        try:
            # å¤§ä¼šå­˜åœ¨ãƒã‚§ãƒƒã‚¯
            from app.models import Competition
            competition = db.query(Competition).filter_by(competition_id=competition_id).first()
            if not competition:
                raise HTTPException(status_code=400, detail=f"å¤§ä¼šID '{competition_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            if overwrite and competition_id:
                db.query(FlexibleSensorMapping).filter_by(competition_id=competition_id).delete()
            
            content = await mapping_file.read()
            df = pd.read_csv(io.BytesIO(content))
            
            # å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
            if 'user_id' not in df.columns:
                raise HTTPException(status_code=400, detail="user_idåˆ—ãŒå¿…è¦ã§ã™")
            
            # user_idé‡è¤‡ãƒã‚§ãƒƒã‚¯
            duplicate_users = df[df['user_id'].duplicated()]['user_id'].tolist()
            if duplicate_users:
                raise HTTPException(
                    status_code=400, 
                    detail=f"user_idã«é‡è¤‡ãŒã‚ã‚Šã¾ã™: {duplicate_users}"
                )
            
            # èªè­˜ã™ã‚‹ã‚»ãƒ³ã‚µãƒ¼åˆ—ã®ã¿ï¼ˆå›ºå®šåˆ—åï¼‰- å€‹äººãƒ‡ãƒ¼ã‚¿ã®ã¿
            recognized_sensor_columns = {
                'skin_temp_sensor_id': SensorType.SKIN_TEMPERATURE,
                'core_temp_sensor_id': SensorType.CORE_TEMPERATURE,
                'heart_rate_sensor_id': SensorType.HEART_RATE
                # WBGTã¯ç’°å¢ƒãƒ‡ãƒ¼ã‚¿ãªã®ã§ãƒãƒƒãƒ”ãƒ³ã‚°ä¸è¦
            }
            
            # èªè­˜ã™ã‚‹åˆ—ãƒªã‚¹ãƒˆï¼ˆuser_id + ã‚»ãƒ³ã‚µãƒ¼åˆ—ã®ã¿ï¼‰
            recognized_columns = {'user_id'}.union(set(recognized_sensor_columns.keys()))
            
            processed = 0
            skipped = 0
            errors = []
            
            for _, row in df.iterrows():
                user_id = str(row.get('user_id', '')).strip()
                
                if not user_id:
                    skipped += 1
                    continue
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼å­˜åœ¨ãƒã‚§ãƒƒã‚¯
                from app.models import User
                user = db.query(User).filter_by(user_id=user_id).first()
                if not user:
                    skipped += 1
                    errors.append(f"æœªç™»éŒ²ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_id}")
                    continue
                
                # ã‚»ãƒ³ã‚µãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°å‡¦ç†
                for col_name, sensor_type in recognized_sensor_columns.items():
                    sensor_id = str(row.get(col_name, '')).strip()
                    
                    if sensor_id and sensor_id != 'nan':
                        # ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ä½œæˆ
                        mapping = FlexibleSensorMapping(
                            user_id=user_id,
                            competition_id=competition_id,
                            sensor_id=sensor_id,
                            sensor_type=sensor_type,
                            subject_name=str(row.get('subject_name', '')).strip() or None,
                            device_type=col_name,
                            is_active=True
                        )
                        db.add(mapping)
                
                processed += 1
            
            db.commit()
            
            return MappingResponse(
                success=True,
                message=f"ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’{processed}ä»¶å‡¦ç†ã—ã¾ã—ãŸï¼ˆã‚¹ã‚­ãƒƒãƒ—: {skipped}ä»¶ï¼‰",
                total_records=len(df),
                processed_records=processed,
                skipped_records=skipped,
                errors=errors
            )
            
        except Exception as e:
            db.rollback()
            raise HTTPException(status_code=400, detail=f"ãƒãƒƒãƒ”ãƒ³ã‚°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def get_data_summary(
        self,
        db: Session,
        competition_id: Optional[str] = None
    ) -> DataSummaryResponse:
        """ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼å–å¾—"""
        
        # ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
        query = db.query(RawSensorData)
        if competition_id:
            query = query.filter_by(competition_id=competition_id)
        
        total_records = query.count()
        mapped_records = query.filter(RawSensorData.mapping_status == SensorDataStatus.MAPPED).count()
        unmapped_records = query.filter(RawSensorData.mapping_status == SensorDataStatus.UNMAPPED).count()
        
        # ã‚»ãƒ³ã‚µãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
        sensor_counts = {}
        for sensor_type in SensorType:
            count = query.filter(RawSensorData.sensor_type == sensor_type).count()
            sensor_counts[sensor_type.value] = count
        
        wbgt_count = db.query(WBGTData)
        if competition_id:
            wbgt_count = wbgt_count.filter_by(competition_id=competition_id)
        wbgt_count = wbgt_count.count()
        
        mapping_count = db.query(FlexibleSensorMapping)
        if competition_id:
            mapping_count = mapping_count.filter_by(competition_id=competition_id)
        mapping_count = mapping_count.count()
        
        return DataSummaryResponse(
            total_sensor_records=total_records,
            mapped_records=mapped_records,
            unmapped_records=unmapped_records,
            sensor_type_counts=sensor_counts,
            wbgt_records=wbgt_count,
            mapping_records=mapping_count,
            competition_id=competition_id
        )

    def get_mapping_status(
        self,
        db: Session,
        competition_id: Optional[str] = None
    ) -> MappingStatusResponse:
        """ãƒãƒƒãƒ”ãƒ³ã‚°çŠ¶æ³ç¢ºèª"""
        
        query = db.query(RawSensorData)
        if competition_id:
            query = query.filter_by(competition_id=competition_id)
        
        status_counts = {}
        for status in SensorDataStatus:
            count = query.filter_by(mapping_status=status).count()
            status_counts[status.value] = count
        
        unmapped_by_type = {}
        for sensor_type in SensorType:
            count = query.filter(
                RawSensorData.sensor_type == sensor_type,
                RawSensorData.mapping_status == SensorDataStatus.UNMAPPED
            ).count()
            unmapped_by_type[sensor_type.value] = count
        
        return MappingStatusResponse(
            status_counts=status_counts,
            unmapped_by_sensor_type=unmapped_by_type,
            competition_id=competition_id
        )

    def get_unmapped_sensors(
        self,
        db: Session,
        sensor_type: Optional[SensorType] = None,
        competition_id: Optional[str] = None,
        limit: int = 100
    ) -> List[Dict[str, Any]]:
        """æœªãƒãƒƒãƒ—ã‚»ãƒ³ã‚µãƒ¼ä¸€è¦§å–å¾—"""
        
        query = db.query(RawSensorData).filter_by(mapping_status=SensorDataStatus.UNMAPPED)
        
        if sensor_type:
            query = query.filter_by(sensor_type=sensor_type)
        if competition_id:
            query = query.filter_by(competition_id=competition_id)
        
        # ã‚»ãƒ³ã‚µãƒ¼IDã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        unmapped_sensors = query.with_entities(
            RawSensorData.sensor_id,
            RawSensorData.sensor_type,
            RawSensorData.competition_id
        ).distinct().limit(limit).all()
        
        return [
            {
                'sensor_id': sensor.sensor_id,
                'sensor_type': sensor.sensor_type.value,
                'competition_id': sensor.competition_id
            }
            for sensor in unmapped_sensors
        ]