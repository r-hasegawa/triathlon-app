import pandas as pd
import io
from fastapi import UploadFile, HTTPException
from sqlalchemy.orm import Session
from typing import Optional, Dict, Any, List
from datetime import datetime
from app.models.flexible_sensor_data import (
    RawSensorData, FlexibleSensorMapping,
    SkinTemperatureData, CoreTemperatureData, 
    HeartRateData, WBGTData, SensorDataStatus, SensorType
)
from app.schemas.sensor_data import (
    UploadResponse, MappingResponse,
    DataSummaryResponse, MappingStatusResponse
)

class FlexibleCSVService:
    
    async def process_sensor_data_only(
        self,
        sensor_file: UploadFile,
        sensor_type: SensorType,
        competition_id: str,  # âœ… Optional[str] â†’ str (å¿…é ˆ)
        db: Session
    ) -> UploadResponse:
        """ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ã¿å‡¦ç†"""
        try:
            # âœ… å¤§ä¼šå­˜åœ¨ãƒã‚§ãƒƒã‚¯è¿½åŠ 
            from app.models import Competition
            competition = db.query(Competition).filter_by(competition_id=competition_id).first()
            if not competition:
                raise HTTPException(status_code=400, detail=f"å¤§ä¼šID '{competition_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            content = await sensor_file.read()
            df = pd.read_csv(io.BytesIO(content))
            
            processed = 0
            
            for _, row in df.iterrows():
                raw_data = RawSensorData(
                    sensor_type=sensor_type,
                    sensor_id=str(row.get('sensor_id', '')),
                    timestamp=pd.to_datetime(row.get('timestamp')),
                    data_values=str(row.get('value', 0)),
                    competition_id=competition_id,  # âœ… å¿…é ˆã§è¨­å®š
                    mapping_status=SensorDataStatus.UNMAPPED,
                    raw_data=row.to_json()
                )
                db.add(raw_data)
                processed += 1
            
            db.commit()
            
            return UploadResponse(
                success=True,
                message=f"{sensor_type.value}ãƒ‡ãƒ¼ã‚¿ã‚’{processed}ä»¶å‡¦ç†ã—ã¾ã—ãŸï¼ˆå¤§ä¼š: {competition.name}ï¼‰",
                total_records=len(df),
                processed_records=processed
            )
            
        except Exception as e:
            db.rollback()
            raise HTTPException(status_code=400, detail=f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")

    async def process_wbgt_data(
        self,
        wbgt_file: UploadFile,
        competition_id: Optional[str],
        db: Session,
        overwrite: bool = True
    ) -> UploadResponse:
        """WBGTç’°å¢ƒãƒ‡ãƒ¼ã‚¿å‡¦ç†ï¼ˆ1å¤§ä¼š1ã¤ã€ä¸Šæ›¸ãå¯¾å¿œï¼‰"""
        try:
            # ä¸Šæ›¸ãå‡¦ç†ï¼šæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
            if overwrite and competition_id:
                deleted_count = db.query(WBGTData).filter_by(competition_id=competition_id).delete()
                db.commit()
                print(f"æ—¢å­˜WBGTãƒ‡ãƒ¼ã‚¿{deleted_count}ä»¶ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            
            content = await wbgt_file.read()
            df = pd.read_csv(io.BytesIO(content))
            
            processed = 0
            
            for _, row in df.iterrows():
                wbgt_data = WBGTData(
                    timestamp=pd.to_datetime(row.get('timestamp')),
                    wbgt_value=float(row.get('wbgt_value', 0)),
                    air_temperature=float(row.get('temperature', 0)) if pd.notna(row.get('temperature')) else None,
                    humidity=float(row.get('humidity', 0)) if pd.notna(row.get('humidity')) else None,
                    location=str(row.get('location', '')),
                    competition_id=competition_id,
                    station_id=str(row.get('station_id', 'WBGT_STATION'))
                )
                db.add(wbgt_data)
                processed += 1
            
            db.commit()
            
            return UploadResponse(
                success=True,
                message=f"WBGTãƒ‡ãƒ¼ã‚¿ã‚’{processed}ä»¶å‡¦ç†ã—ã¾ã—ãŸï¼ˆä¸Šæ›¸ã: {overwrite}ï¼‰",
                total_records=len(df),
                processed_records=processed
            )
            
        except Exception as e:
            db.rollback()
            raise HTTPException(status_code=400, detail=f"WBGTå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")


    async def process_mapping_data(
        self,
        mapping_file: UploadFile,
        competition_id: str,  # å¿…é ˆ
        db: Session,
        overwrite: bool = True
    ) -> MappingResponse:
        """æŸ”è»Ÿãªãƒãƒƒãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
        try:
            # å¤§ä¼šå­˜åœ¨ãƒã‚§ãƒƒã‚¯
            from app.models import Competition
            competition = db.query(Competition).filter_by(competition_id=competition_id).first()
            if not competition:
                raise HTTPException(status_code=400, detail=f"å¤§ä¼šID '{competition_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            if overwrite and competition_id:
                db.query(FlexibleSensorMapping).filter_by(competition_id=competition_id).delete()
            
            content = await mapping_file.read()
            df = pd.read_csv(io.BytesIO(content))
            
            # å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
            if 'user_id' not in df.columns:
                raise HTTPException(status_code=400, detail="user_idåˆ—ãŒå¿…è¦ã§ã™")
            
            # user_idé‡è¤‡ãƒã‚§ãƒƒã‚¯
            duplicate_users = df[df['user_id'].duplicated()]['user_id'].tolist()
            if duplicate_users:
                raise HTTPException(
                    status_code=400, 
                    detail=f"user_idã«é‡è¤‡ãŒã‚ã‚Šã¾ã™: {duplicate_users}"
                )
            
            # èªè­˜ã™ã‚‹ã‚»ãƒ³ã‚µãƒ¼åˆ—ã®ã¿ï¼ˆå›ºå®šåˆ—åï¼‰- å€‹äººãƒ‡ãƒ¼ã‚¿ã®ã¿
            recognized_sensor_columns = {
                'skin_temp_sensor_id': SensorType.SKIN_TEMPERATURE,
                'core_temp_sensor_id': SensorType.CORE_TEMPERATURE,
                'heart_rate_sensor_id': SensorType.HEART_RATE
                # WBGTã¯ç’°å¢ƒãƒ‡ãƒ¼ã‚¿ãªã®ã§ãƒãƒƒãƒ”ãƒ³ã‚°ä¸è¦
            }
            
            # èªè­˜ã™ã‚‹åˆ—ãƒªã‚¹ãƒˆï¼ˆuser_id + ã‚»ãƒ³ã‚µãƒ¼åˆ—ã®ã¿ï¼‰
            recognized_columns = {'user_id'} | set(recognized_sensor_columns.keys())
            
            # ç ´æ£„ã•ã‚Œã‚‹åˆ—ã‚’ãƒ­ã‚°å‡ºåŠ›
            ignored_columns = set(df.columns) - recognized_columns
            if ignored_columns:
                print(f"ğŸ—‘ï¸  ç„¡è¦–ã•ã‚Œã‚‹åˆ—: {list(ignored_columns)}")
            
            processed_mappings = 0
            processed_users = 0
            updated_sensor_data = 0
            
            for _, row in df.iterrows():
                user_id = str(row.get('user_id', '')).strip()
                if not user_id:
                    continue
                
                processed_users += 1
                
                # èªè­˜ã•ã‚Œã‚‹ã‚»ãƒ³ã‚µãƒ¼åˆ—ã®ã¿å‡¦ç†
                for col_name, sensor_type in recognized_sensor_columns.items():
                    if col_name in df.columns and pd.notna(row.get(col_name)):
                        sensor_id = str(row[col_name]).strip()
                        if sensor_id:
                            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å­˜åœ¨ãƒã‚§ãƒƒã‚¯
                            from app.models import User
                            user = db.query(User).filter_by(user_id=user_id).first()
                            if not user:
                                print(f"âš ï¸  User {user_id} not found, skipping mapping")
                                continue
                            
                            # åŒä¸€å¤§ä¼šå†…ã§ã®é‡è¤‡ã‚»ãƒ³ã‚µãƒ¼ãƒã‚§ãƒƒã‚¯
                            existing_mapping = db.query(FlexibleSensorMapping).filter_by(
                                sensor_id=sensor_id,
                                sensor_type=sensor_type,
                                competition_id=competition_id
                            ).first()
                            
                            if existing_mapping:
                                print(f"âš ï¸  Sensor {sensor_id} already mapped to {existing_mapping.user_id}")
                                continue
                            
                            # 1. ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
                            mapping_data = FlexibleSensorMapping(
                                user_id=user_id,
                                sensor_id=sensor_id,
                                sensor_type=sensor_type,
                                competition_id=competition_id
                                # subject_nameãªã©ã®é–¢ä¿‚ãªã„åˆ—ã¯ä¿å­˜ã—ãªã„
                            )
                            db.add(mapping_data)
                            processed_mappings += 1
                            
                            # ğŸ†• 2. å¯¾å¿œã™ã‚‹ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®çŠ¶æ…‹ã‚’æ›´æ–°
                            from datetime import datetime
                            updated_records = db.query(RawSensorData).filter_by(
                                sensor_id=sensor_id,
                                sensor_type=sensor_type,
                                competition_id=competition_id,
                                mapping_status=SensorDataStatus.UNMAPPED
                            ).update({
                                'mapping_status': SensorDataStatus.MAPPED,
                                'mapped_user_id': user_id,
                                'mapped_at': datetime.now()
                            })
                            
                            updated_sensor_data += updated_records
                            print(f"âœ… Mapped {sensor_id} to {user_id}, updated {updated_records} sensor records")
            
            db.commit()
            
            return MappingResponse(
                success=True,
                message=f"ãƒ¦ãƒ¼ã‚¶ãƒ¼{processed_users}äººã€ã‚»ãƒ³ã‚µãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°{processed_mappings}ä»¶ã‚’å‡¦ç†ã—ã€ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿{updated_sensor_data}ä»¶ã‚’æ›´æ–°ã—ã¾ã—ãŸï¼ˆå¤§ä¼š: {competition.name}ï¼‰",
                mapped_sensors=processed_mappings
            )
            
        except Exception as e:
            db.rollback()
            raise HTTPException(status_code=400, detail=f"ãƒãƒƒãƒ”ãƒ³ã‚°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def get_data_summary(
        self,
        db: Session,
        competition_id: Optional[str] = None
    ) -> DataSummaryResponse:
        """ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ã‚µãƒãƒªãƒ¼"""
        
        query = db.query(RawSensorData)
        if competition_id:
            query = query.filter_by(competition_id=competition_id)
        
        total_records = query.count()
        mapped_records = query.filter_by(mapping_status=SensorDataStatus.MAPPED).count()
        unmapped_records = query.filter_by(mapping_status=SensorDataStatus.UNMAPPED).count()
        
        sensor_counts = {}
        for sensor_type in SensorType:
            count = query.filter_by(sensor_type=sensor_type).count()
            sensor_counts[sensor_type.value] = count
        
        wbgt_count = db.query(WBGTData)
        if competition_id:
            wbgt_count = wbgt_count.filter_by(competition_id=competition_id)
        wbgt_count = wbgt_count.count()
        
        mapping_count = db.query(FlexibleSensorMapping)
        if competition_id:
            mapping_count = mapping_count.filter_by(competition_id=competition_id)
        mapping_count = mapping_count.count()
        
        return DataSummaryResponse(
            total_sensor_records=total_records,
            mapped_records=mapped_records,
            unmapped_records=unmapped_records,
            sensor_type_counts=sensor_counts,
            wbgt_records=wbgt_count,
            mapping_records=mapping_count,
            competition_id=competition_id
        )

    def get_mapping_status(
        self,
        db: Session,
        competition_id: Optional[str] = None
    ) -> MappingStatusResponse:
        """ãƒãƒƒãƒ”ãƒ³ã‚°çŠ¶æ³ç¢ºèª"""
        
        query = db.query(RawSensorData)
        if competition_id:
            query = query.filter_by(competition_id=competition_id)
        
        status_counts = {}
        for status in SensorDataStatus:
            count = query.filter_by(mapping_status=status).count()
            status_counts[status.value] = count
        
        unmapped_by_type = {}
        for sensor_type in SensorType:
            count = query.filter(
                RawSensorData.sensor_type == sensor_type,
                RawSensorData.mapping_status == SensorDataStatus.UNMAPPED
            ).count()
            unmapped_by_type[sensor_type.value] = count
        
        return MappingStatusResponse(
            status_counts=status_counts,
            unmapped_by_sensor_type=unmapped_by_type,
            competition_id=competition_id
        )

    def get_unmapped_sensors(
        self,
        db: Session,
        sensor_type: Optional[SensorType] = None,
        competition_id: Optional[str] = None
    ) -> Dict[str, List[str]]:
        """æœªãƒãƒƒãƒ”ãƒ³ã‚°ã‚»ãƒ³ã‚µãƒ¼ä¸€è¦§"""
        
        query = db.query(RawSensorData).filter_by(mapping_status=SensorDataStatus.UNMAPPED)
        
        if competition_id:
            query = query.filter_by(competition_id=competition_id)
        
        if sensor_type:
            query = query.filter_by(sensor_type=sensor_type)
        
        results = query.distinct(RawSensorData.sensor_id, RawSensorData.sensor_type).all()
        
        unmapped_sensors = {}
        for record in results:
            type_key = record.sensor_type.value
            if type_key not in unmapped_sensors:
                unmapped_sensors[type_key] = []
            if record.sensor_id not in unmapped_sensors[type_key]:
                unmapped_sensors[type_key].append(record.sensor_id)
        
        return unmapped_sensors

    # === ã‚µãƒ³ãƒ—ãƒ«CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ ===

    def get_mapping_csv_examples():
        """ãƒãƒƒãƒ”ãƒ³ã‚°CSVã®ä¾‹ã‚’è¿”ã™"""
        return {
            "minimal": """user_id
    test_user_001
    user002
    user003""",
            
            "with_ignored_columns": """user_id,subject_name,department,age
    test_user_001,ç”°ä¸­å¤ªéƒ,é–‹ç™ºéƒ¨,25
    user002,ä½è—¤èŠ±å­,å–¶æ¥­éƒ¨,30
    user003,å±±ç”°æ¬¡éƒ,ç·å‹™éƒ¨,28""",
            
            "with_single_sensor": """user_id,subject_name,skin_temp_sensor_id,other_info
    test_user_001,ç”°ä¸­å¤ªéƒ,SKIN_SENSOR_001,å‚™è€ƒ1
    user002,ä½è—¤èŠ±å­,SKIN_SENSOR_002,å‚™è€ƒ2
    user003,å±±ç”°æ¬¡éƒ,SKIN_SENSOR_003,å‚™è€ƒ3""",
            
            "with_multiple_sensors": """user_id,skin_temp_sensor_id,core_temp_sensor_id,heart_rate_sensor_id,extra_column
    test_user_001,SKIN_SENSOR_001,CORE_SENSOR_001,HR_SENSOR_001,ç„¡è¦–ã•ã‚Œã‚‹
    user002,SKIN_SENSOR_002,CORE_SENSOR_002,HR_SENSOR_002,ã“ã‚Œã‚‚ç„¡è¦–
    user003,SKIN_SENSOR_003,,HR_SENSOR_003,""",
            
            "partial_mapping": """user_id,subject_name,notes,skin_temp_sensor_id
    test_user_001,ç”°ä¸­å¤ªéƒ,ãƒ¡ãƒ¢1,SKIN_SENSOR_001
    user002,ä½è—¤èŠ±å­,ãƒ¡ãƒ¢2,
    user003,å±±ç”°æ¬¡éƒ,ãƒ¡ãƒ¢3,SKIN_SENSOR_003"""
        }